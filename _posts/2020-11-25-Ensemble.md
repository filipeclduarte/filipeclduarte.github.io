# Ensemble Learning

Combine models achieve better results than using one model for classification Kuncheva (2014). Also, an ensemble classifier is just one classifier model.

**Reasons to combine models**

 I. **Statistical**: It is better to average several models than choose only one. 
 
 II. **Computational**: Small sample size or too much data; Imperfect training algorithm. 
 
 III. **Representational**: Complex boundary can be approximated with the desired precision by simple boundaries. An ensemble of linear classifiers can approximate a highly nonlinear classification boundary. 

**Ensemble Learning consists of three phases**

1. Generation

It is preferable to use simpler models like Perceptrons or Decision Trees for the pool to guarantee diversity. We could use a "monolithic" model or not, for example, using several different algorithms. 

2. Selection

3. Fusion


**Random Linear Oracle**

The Random Linear Oracle (RLO) is a method that combines the classifier fusion and classifier selection approaches (Kuncheva, 2014). Linear Oracle is a mini-ensemble consisting of only two classifiers, which choose the best classifier for a given training instance. In this sense, we could think that Oracle is the best model selector. 

![Kuncheva (2014)](/images/RLO.png)


**Reference**

Kuncheva, Ludmila I. Combining Pattern Classifiers. Methods and Algorithms: Wiley, 2014.
